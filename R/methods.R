#' Confidence intervals
#'
#' Computes confidence intervals for the CGAIM parameters.
#'
#' @param object A \code{cgaim} object.
#' @param parm A numeric or character vector indicating the terms for which
#'    to compute the confidence intervals. Indicates only indices and 
#'    covariates, not individual alpha coefficients. If missing, includes
#'    all terms.
#' @param level The level of confidence intervals. Default to 95\%.
#' @param type A character vector giving the type(s) of confidence intervals
#'    to compute. \code{"normal"} compute classical confidence intervals
#'    based on normal approximation. The others are all based on bootstrap.
#'    \code{"boot.pct"} computes intervals as percentiles of the bootstrap
#'    distribution. \code{"boot.t"} computes studentized bootstrap intervals.
#'    \code{"boot.bca"} (still experimental, use at your own risk) computes bias-corrected and accelerated bootstrap
#'    intervals. Can include several types.
#' @param boot.type Character indicating the type of resampling for bootstrap.
#'    If \code{boot.type = "residuals"} (the default), residuals are
#'    resampled and added to fitted valued to create a new bootstrapped 
#'    response sample. If \code{boot.type = "pairs"}, new samples are
#'    created by resampling pairs, i.e. both response and predictors.
#' @param bsamples A n x B matrix of observation indices used for user-specified 
#'    bootstrap samples. If \code{NULL}, samples are generated internally.
#' @param B Number of bootstrap samples to generate if \code{bsamples = NULL}.
#' @param l Block length for block-bootstrap. Samples are generated by
#'    resampling block of observation of length \code{l}. The classical
#'    bootstrap corresponds to \code{l = 1} (the default).
#' @param m If \code{type} includes \code{"boot.bca"}, the number of jackknife 
#'    blocks used to compute the acceleration parameter.
#' @param applyFun The 'apply' function used to estimate the CGAIM on each
#'    bootstrap sample. Used to parallelize computation. Note that 
#'    \code{applyFun = "mclapply"} does not work on windows. Default to
#'    \code{"lapply"}, i.e. without parallelization.
#' @param cl A cluster object to be used when 
#'    \code{applyFun = "parLapply"}. See \code{\link[parallel]{parLapply}}.
#' @param ... Additional parameters to be passed to the parallel function. See
#'    \code{\link[parallel]{mclapply}} or \code{\link[parallel]{parLapply}}.
#'
#' Computes confidence intervals for the parameters of \code{object}. The
#'    \code{"normal"} confidence intervals are based on the covariance matrices
#'    returned by \code{cgaim}. Note that these are rough estimates. 
#'    
#' Several types of bootstrap confidence intervals can be computed, based on
#'    extensive theory on the subject. Note however that this is computationally
#'    intensive. For quicker execution, pass \code{type = "normal"} only to
#'    prevent the function from computing bootstrap samples.   
#'
#' Note that only \code{"normal"} confidence intervals are available for
#'    the ridge functions yet. However, they match the bayesian intervals 
#'    developed for GAM and SCAM.
#'
#' @return A named list with elements \code{alpha}, \code{beta} and \code{g}.
#'    Each is a list containing as elements the different types of 
#'    intervals given in \code{type}. In addition, contains the generated
#'    bootstrap values as well as the bias and acceleration computed if
#'    \code{"boot.bca"} is in \code{type}.
#'
#' @references
#'   Pya, N., Wood, S.N., 2015. Shape constrained additive models. 
#'    Stat. Comput. 25, 543–559. 
#'   Wood, S.N., 2017. Generalized Additive Models: An Introduction with R, 
#'     2nd ed, Texts in Statistical Science. Chapman and Hall/CRC.
#'   DiCiccio, T.J., Efron, B., 1996. Bootstrap Confidence Intervals. 
#'     Statistical Science 11, 189–212.
#'   Carpenter, J., Bithell, J., 2000. Bootstrap confidence intervals: 
#'     when, which, what? A practical guide for medical statisticians. 
#'     Statistics in Medicine 19, 1141–1164.
#'
#' @export
confint.cgaim <- function(object, parm, level = 0.95, 
  type = c("normal", "boot.pct", "boot.t", "boot.bca"), 
  boot.type = c("residuals", "pairs"), bsamples = NULL, B = 100, l = 1,
  m = 20, applyFun = c("lapply", "mclapply", "parLapply"), cl = NULL, ...)
{
  type <- match.arg(type, several.ok = TRUE)
  p <- length(object$alpha)
  ptot <- ncol(object$gfit)
  d <- length(object$index)
  n <- length(object$fitted)
  if (missing(parm)){
    parm <- 1:ptot
  } else {      
    if (is.character(parm)){
      parm <- which(names(object$alpha) %in% parm)
    }
    if (!any(parm %in% 1:p)){
      stop("'parm' incorrectly specified. Please specify index either with their labels or with their number")
    }
  }
  aparm <- intersect(parm, 1:p)
  alims <- c((1 - level) / 2, 1 - (1 - level) / 2)
  level.labels <- sprintf("%s%%", alims * 100)
  dvec <- which(object$index %in% aparm)
  alphas <- unlist(object$alpha[aparm])
  ses <- diag(object$avcov)[dvec]
  betas <- object$beta[parm + 1]
  bses <- diag(object$bvcov)[parm + 1]
  gs <- object$gfit[,parm, drop = FALSE]
  gses <- object$gse[,parm, drop = FALSE]
  alphaCI <- list()
  betaCI <- list()
  gCI <- list()
  if ("normal" %in% type){
    tlims <- stats::qt(alims, n - d - p)
    conflims <- sapply(ses, "*", tlims)
    alphaCI$normal <- t(matrix(alphas, 2, length(dvec), byrow = TRUE) + conflims)
    conflims <- sapply(bses, "*", tlims)
    betaCI$normal <- t(matrix(betas, 2, length(parm), byrow = TRUE) + conflims)
    colnames(alphaCI$normal) <- colnames(betaCI$normal) <- level.labels
    rownames(betaCI$normal) <- names(betas)
    if (object$algo.control$smooth_method == "scam"){      
      gCI$normal <- array(0, c(n, length(parm), 2), 
        dimnames = list(rownames(gs), colnames(gs), level.labels))
      for (j in 1:length(parm)){
        gconf <- t(sapply(gses[,j], "*", tlims))
        gCI$normal[,j,] <- apply(gconf, 2, "+", gs[,j])
      }
    } else {
      warning("Cannot provide confidence interval for ridge functions with the chosen smoothing method")
    }
  } 
  if (any(c("boot.pct", "boot.bca", "boot.t") %in% type)){
    boot.type <- match.arg(boot.type)
    applyFun <- match.arg(applyFun)
    if (is.null(bsamples)){
      bsamples <- sample(seq_len(n - l + 1), (n * B) / l, replace = TRUE)
      suppressWarnings(bsamples <- matrix(sapply(bsamples, function(b) b:(b + l - 1)), 
        nrow = n, ncol = B))
    } else {
      B <- ncol(bsamples)
    }
    if (is.null(object$y)){
      stop("Cannot find data in object. keep.data must be set to TRUE to use bootstrap confidence intervals.")
    }
    pars <- object$algo.control
    pars$x <- object$x
    pars$index <- object$index
    pars$smooth.control <- object$smooth.control
    pars$alpha.control <- object$alpha.control
    pars$w <- object$weights
    bootRes <- function(b, object, pars){
      pars$y <- object$fitted + object$residuals[b]
      attributes(pars$y) <- attributes(object$y)
      resb <- do.call("gaim_gn", pars)
      list(resb$alpha[dvec], diag(resb$avcov)[dvec], resb$beta[parm + 1], 
        diag(resb$bvcov)[parm + 1], resb$gfit[,parm], resb$gse[,parm])
    }
    bootPairs <- function(b, object, pars){
      pars$y <- object$y[b]
      attr(pars$y, "varname") <- attr(object$y, "varname")
      pars$x <- object$x[b,]
      if (!is.null(object$smooth.control$Xcov)){ 
        pars$smooth.control$Xcov <- object$smooth.control$Xcov[b,]
      }
      pars$w <- object$w[b]
      resb <- do.call("gaim_gn", pars)
      list(resb$alpha[dvec], diag(resb$avcov)[dvec], resb$beta[parm + 1], 
        diag(resb$bvcov)[parm], resb$gfit[,parm], resb$gse[,parm])
    }   
    bootFun <- ifelse(boot.type == "pairs", bootPairs, bootRes)
    resb <- switch(applyFun,
      lapply = lapply(as.data.frame(bsamples), bootFun, 
        object = object, pars = pars),
      mclapply = parallel::mclapply(as.data.frame(bsamples), bootFun, 
        object = object, pars = pars, ...),
      parLapply = {
        if (is.null(cl)) stop("'cl' must be provided to use 'parLapply'")
        parallel::clusterExport(cl, ls(), envir = environment())
        parallel::clusterEvalQ(cl, library(cgaim))
        parallel::parLapply(cl, as.data.frame(bsamples), bootFun, 
          object = object, pars = pars, ...)
      }
    )
    alphab <- sapply(resb, "[[", 1)
    rownames(alphab) <- names(alphas)
    seb <- sapply(resb, "[[", 2)
    betab <- sapply(resb, "[[", 3)
    sebb <- sapply(resb, "[[", 4)
#    gb <- sapply(resb, "[[", 5, simplify = "array")
#    gesb <- sapply(resb, "[[", 6, simplify = "array")
    if (length(parm) == 1){ 
      betab <- t(as.matrix(betab))
#      gb <- array(gb, c(n, 1, B))
#      gesb <- array(gesb, c(n, 1, B))
    }
    rownames(betab) <- names(betas)
    if ("boot.pct" %in% type){
      alphaCI$boot.pct <- t(apply(alphab, 1, stats::quantile, 
        alims, na.rm = TRUE))
      betaCI$boot.pct <- t(apply(betab, 1, stats::quantile, 
        alims, na.rm = TRUE))
#      gCI$boot.pct <- apply(gb, 1:2, quantile, alims, na.rm = TRUE)
#      gCI$boot.pct <- aperm(gCI$boot.pct, c(2,3,1))
    } 
    if ("boot.t" %in% type){
      tb <- (alphab - matrix(alphas, d, B)) / seb
      tpct <- apply(tb, 1, stats::quantile, alims, na.rm = TRUE)
      alphaCI$boot.t <- t(matrix(alphas, 2, d, byrow = TRUE) + 
        (tpct * matrix(ses, 2, d, byrow = TRUE)))
      alphaCI$boot.t <- alphaCI$boot.t[,2:1]
      colnames(alphaCI$boot.t) <- level.labels
      tbb <- (betab - matrix(betas, length(parm), B)) / sebb
      tbpct <- apply(tbb, 1, stats::quantile, alims, na.rm = TRUE)
      betaCI$boot.t <- t(matrix(betas, 2, length(parm), byrow = TRUE) + 
        (tbpct * matrix(bses, 2, length(parm), byrow = TRUE)))
      betaCI$boot.t <- betaCI$boot.t[,2:1, drop = FALSE]
      colnames(betaCI$boot.t) <- level.labels
#      gtb <- gb
#      for (b in 1:B){
#        gtb[,,b] <- (gb[,,b] - gs) / gses
#      }
#      gCI$boot.t <- aperm(apply(gtb, 1:2, quantile, alims, na.rm = TRUE), c(2,3,1))
#      gCI$boot.t[,,1] <- (gCI$boot.t[,,1] * gses) + gs
#      gCI$boot.t[,,2] <- (gCI$boot.t[,,2] * gses) + gs
    }
    if ("boot.bca" %in% type){
      z0 <- mapply(function(tt, t0){stats::qnorm(mean(tt < t0))},
        as.data.frame(t(alphab)), alphas)
      z0b <- mapply(function(tt, t0){stats::qnorm(mean(tt < t0))},
        as.data.frame(t(betab)), betas)
      jksamps <- split(1:n, sort(rep_len(1:m,n)))
      jksamps <- lapply(jksamps, function(ij) setdiff(1:n, ij))
      resjk <- switch(applyFun,
        lapply = lapply(jksamps, bootPairs, 
          object = object, pars = pars)      ,
        mclapply = parallel::mclapply(jksamps, bootPairs, 
          object = object, pars = pars, ...),
        parLapply = parallel::parLapply(cl, jksamps, bootPairs, 
          object = object, pars = pars, ...)
      )      
      alphamat <- sapply(resjk, "[[", 1)
      betamat <- sapply(resjk, "[[", 3)
      if (length(parm) == 1) betamat <- t(as.matrix(betamat))
      a <- apply(alphamat, 1, function(u){
        t. <- (mean(u) - u) * (m - 1)
        (1/6) * sum(t.^3)/(sum(t.^2))^1.5
      })
      ab <- apply(betamat, 1, function(u){
        t. <- (mean(u) - u) * (m - 1)
        (1/6) * sum(t.^3)/(sum(t.^2))^1.5
      })
      bca <- sapply(alims, function(lev){
        za <- stats::qnorm(lev)
        correc <- z0 + (z0 + za) / 
          (1 - a * (z0 + za))
        indB <- trunc(stats::pnorm(correc) * B)
        indB <- pmin(pmax(indB, 1), B)
        lim <- mapply(function(x, i) sort(x)[i], 
          as.data.frame(t(alphab)), indB)
      })
      bbca <- sapply(alims, function(lev){
        za <- stats::qnorm(lev)
        correc <- z0b + (z0b + za) / 
          (1 - ab * (z0b + za))
        indB <- trunc(stats::pnorm(correc) * B)
        indB <- pmin(pmax(indB, 1), B)
        lim <- mapply(function(x, i) sort(x)[i], 
          as.data.frame(t(betab)), indB)
      })
      if (length(parm) == 1) bbca <- t(as.matrix(bbca))
      colnames(bca) <- colnames(bbca) <- level.labels
      alphaCI$boot.bca <- bca
      alphaCI$acceleration <- a
      alphaCI$bias <- z0
      betaCI$boot.bca <- bbca
      betaCI$acceleration <- ab
      betaCI$bias <- z0b
    }
    alphaCI$alpha.boot <- t(alphab)
    betaCI$beta.boot <- t(betab)
#    gCI$g.boot <- gb
  }
  out <- list(alpha = alphaCI, beta = betaCI, g = gCI)
  return(out)
}

#' Print a cgaim object
#'
#' Default method to print the result from a call to \code{cgaim}.
#'
#' @param x A \code{cgaim} object.
#' @param ... For compatibility with the default \code{print} method. Unused
#'    at the moment.
#'
#' Conveniently prints the formula, \code{beta} and \code{alpha} coefficients
#'    as well as the residual sum of squares.
#'
#' @export
print.cgaim <- function(x, ...){
  cat("Formula:\n")
  trms <- x$terms
  attributes(trms) <- NULL
  print(trms)
  cat("\nCoefficients:\n")
  print(x$beta)
  cat("\nIndices weights:\n")
  for (j in seq_along(x$alpha)){
    cat(names(x$alpha)[j], "\n")
    print(x$alpha[[j]])
  }
  cat("\nResidual sum of squares: ")
  cat(x$rss)
  cat("\n")
}

#' Predictions from a fitted CGAIM object
#'
#' Uses a fitted \code{cgaim} object and computes prediction for the
#'    observed data or new data. Predicts the response, indices or 
#'    ridge functions values at the provided data.
#'
#' @param object A \code{gaim} object.
#' @param newdata A list or data.frame containing the new data to predict.
#'    If missing, fitted values from the model are returned.
#' @param type A character indicating the type of prediction to return.
#'    When \code{type = "response"}, the predicted response is returned. When
#'    \code{type = "terms"}, returns each ridge and smooth function separately.
#'    When \code{type = "indices"}, returns predicted indices values.
#' @param select A numeric or character vector indicating terms to return
#'    when \code{type = "terms"} or \code{type = "indices"}.
#' @param na.action A function indicating how to treat NA values when 
#'    when \code{newdata} is not missing.
#' @param ... For compatibility with the default \code{predict} method. Unused
#'    at the moment.
#'
#' When \code{newdata} is provided, it must contain all variables used in
#'    the fitted model.
#'
#' @return When \code{type = "response"} returns a vector of predicted response.
#'    When \code{type = "terms"} returns a d-column matrix where d is the 
#'    number of ridge and smooth terms. When \code{type = "indices"}, returns
#'    a p-column matrix where p is the number of created indices.
#'
#' @export
predict.cgaim <- function(object, newdata, 
  type = c("response", "terms", "indices"), select = NULL, 
  na.action = "na.pass", ...)
{
  type <- match.arg(type)
  n <- length(object$fitted)
  p <- length(object$beta) - 1
  mt <- stats::terms(object)
  if (!missing(newdata)){
    mt <- stats::delete.response(mt)
    gind <- attr(mt, "specials")$g
    mfind <- stats::model.frame(mt[gind], data = newdata, 
      na.action = na.action)
    alphas <- object$alpha
    newindex <- mapply("%*%", mfind, alphas)
    colnames(newindex) <- names(alphas)
    if (type == "indices"){
      if (!is.null(select)) newindex <- newindex[,select, drop = F]
      return(newindex)
    }
    Xterms <- data.frame(newindex, newdata[,names(object$covariates)])
    sind <- attr(mt, "specials")$s
    objx <- data.frame(object$indexfit, object$covariates)
    gterms <- matrix(0, nrow(mfind), p)
    for (j in 1:p){
      if (is.numeric(Xterms[[j]])){
        inter_fun <- ifelse(j %in% c(gind, sind), "spline", "approx")
        gterms[,j] <- suppressWarnings(do.call(inter_fun, 
          list(x = objx[,j], y = object$gfit[,j], xout = Xterms[,j]))$y) 
      } else {
        faccoefs <- unique(object$gfit[,j])
        names(faccoefs) <- unique(objx[,j])
        gterms[,j] <- faccoefs[Xterms[,j]]
      }
    }
    colnames(gterms) <- colnames(object$gfit)
    if (type == "terms"){
      if (!is.null(select)) gterms <- gterms[,select, drop = F]
      return(gterms)
    }
    betas <- object$beta
    yhat <- cbind(1, gterms) %*% betas
    return(yhat)
  } else {
    out <- switch(type,
      response = object$fitted,
      terms = object$gfit * matrix(object$beta[-1], n, p, byrow = T),
      indices = object$indexfit
    )
    return(out)
  }
}

#' Plot CGAIM terms
#'
#' Plot method for the ridge and smooth terms of a \code{cgaim} object. If
#'    provided, may also plot confidence intervals.
#'
#' @param x A \code{cgaim} object.
#' @param select A numeric or character vector indicating which terms
#'    to plot.
#' @param ci An object returned by a call to \code{link{confint.cgaim}}. If
#'    \code{NULL}, no confidence interval is drawn.
#' @param ci.type When \code{ci} is not \code{NULL}, which confidence interval
#'    to plot. See \code{link{confint.cgaim}} for the different types. For now,
#'    only normal confidence intervals work.
#' @param ci.plot Whether to plot the confidence intervals as shaded areas
#'    \code{ci.plot = "polygon"} or as lines \code{ci.plot = "lines"}.
#' @param ci.args Additional arguments to be passed to the function used
#'    to draw confidence interval. Either \code{\link[graphics]{polygon}} or
#'    \code{\link[graphics]{lines}}.
#' @param ... Additional graphical parameters for the drawn function. See
#'    \code{link[graphics]{par}}.
#'
#' At the moment, only plots ridge and smooth functions. When several terms
#'    are plotted, waits for user response before displaying the next one.
#'
#' @export
plot.cgaim <- function(x, select = NULL, ci = NULL,
  ci.type = c("normal", "boot.pct", "boot.t", "boot.bca"),
  ci.plot = c("polygon", "lines"), ci.args = list(), ...)
{
  p <- ncol(x$gfit)
  if (is.null(select)){
    select <- seq_len(p)
  }
  if (length(select) > 1) grDevices::devAskNewPage(TRUE)
  xs <- cbind(x$indexfit, x$covariates)
  defParams <- list(ylab = "g", type = "l")
  dots <- list(...)
  if (!is.null(ci)){
    ci.type <- match.arg(ci.type)
    ci.plot <- match.arg(ci.plot)
    allcis <- ci$g[[ci.type]]
    if (ci.plot == "polygon"){
      defArgs <- list(border = NA, col = "grey")      
    }
    if (ci.plot == "lines"){
      defArgs <- list(lty = 2)
    }
    ci.args <- c(ci.args,
      defArgs[!names(defArgs) %in% names(ci.args)])
  }
  for (j in select){
    xy <- cbind(xs[,j], x$gfit[,j])
    xy <- xy[order(xy[,1]),]
    defParams$xlab <- colnames(xs)[j]
    jpars <- c(dots, defParams[!names(defParams) %in% names(dots)])
    jpars$x <- xy[,1]
    jpars$y <- xy[,2]
    if (!is.null(ci)){
      cij <- allcis[,j,]
      if (is.null(jpars$ylim)){
        jpars$ylim <- range(cij)
      }
      do.call(graphics::plot, jpars)
      cixy <- cbind(xs[,j], cij)
      cixy <- cixy[order(cixy[,1]),]
      if (ci.plot == "polygon"){
        ci.args$x <- c(cixy[,1], rev(cixy[,1]))
        ci.args$y <- c(cixy[,2], rev(cixy[,3]))
        do.call(graphics::polygon, ci.args)
        do.call(graphics::points, jpars)
      }
      if (ci.plot == "lines"){
        ci.args$x <- cixy[,1]
        ci.args$y <- cixy[,2]
        do.call(graphics::lines, ci.args)
        ci.args$y <- cixy[,3]
        do.call(graphics::lines, ci.args)
      }
    } else {
      do.call(graphics::plot, jpars)
    }
  }
  invisible()  
}