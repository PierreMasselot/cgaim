#!#############################################################################
#!
#!                       Secondary functions (internally used)                 
#!
#!#############################################################################

#! distributed lags
dlag <- function(x, lags = 1, na.action = na.pass)  #! ADD TIME INDEX
# x: vector of data to lag
# lags: vector of lags to apply
# na.action: action for the NAs generated by the lagging
{
    n <- length(x)
    L <- length(lags)
    maxlag <- max(lags)
    res <- matrix(NA, n, L)
    for (j in 1:L){
        lj <- lags[j]
        res[(lj+1):n,j] <- x[1:(n-lj)]
    }
    res <- do.call(na.action, list(res))
    return(res)
}

dlag_len <- function(x, lag, na.action = na.pass)
# x: vector of data to lag
# lags: maximum lag
# na.action: action for the NAs generated by the lagging
{
  lags <- 0:lag
  return(dlag(x, lags, na.action))
}


#! L2 loss function
L2 <- function(y, yhat, w){ 
    return(weighted.mean((y-yhat)^2, w))
}

#! Initialize alpha coefficients in a single-index model
#! TODO: add possibility to include decreasing alphas
alpha.init <- function(p, y, x, type = c("constant", "runif", "rnorm", "ols"), normalize = TRUE, first.pos = TRUE)
# type: character giving the type of initialization, "contant" attributes the same value to each alpha, "rnorm" and "runif" generates alphas by drawing random numbers respectively from a standard normal distribution and a uniform distribution, "ols" uses ols estimates of y ~ x as initial values
# p: number of coefficients, used only for type = "constant" and "random"
# y, x: response and predictors used for type = "ols"
# normalize: if TRUE the resulting alphas are normalized such that the vector norm is one
# first.pos: if TRUE, the first weight is forced to be positive

# Value: a vector of alpha coefficients of length p (or ncol(x) if type = "ols")
{
    type <- match.arg(type)
    if (type %in% c("constant", "rnorm", "runif") && missing(p)) stop("p is missing")
    if (type == "ols" && (missing(y) || missing(x))) stop("x and y must be provided when type = 'ols'")
    alpha <- switch(type,
        constant = rep(1, p),
        rnorm = rnorm(p),
        runif = runif(p)-.5,
        ols = coef(lm(y ~ 0 + x))
    )
    if (normalize) alpha <- alpha/sqrt(sum(alpha^2))
    if (first.pos) alpha <- sign(alpha[1])*alpha
    return(alpha)
}

#! Derivation by first differences
ppr.der <- function(x, z, gz, alpha){ #! TODO add pooling as in Friedman (1984) or litterature review for numeric derivation
    zord <- order(z)
    gzs <- gz[zord]
    xs <- x[zord,]
    dgzs <- (gzs[3:n] - gzs[1:(n-2)]) / ((xs[3:n,] - xs[1:(n-2),])%*%alpha)
    dgzs <- c(dgzs[1], dgzs, dgzs[n-2])
    dgz <- dgzs[rank(z)]
}

#! Different smoothers
#! Retirer alpha?
spline.smoother <- function(z, y, w, ...){
    sm.fit <- smooth.spline(z, y, w = w, ...)
    gz <- predict(sm.fit, z)$y
    dgz <- predict(sm.fit, z, deriv = 1)$y
    return(list(gz = gz, dgz = dgz))
}

super.smoother <- function(z, y, w, ...){
    gz <- supsmu(z, y, wt = w, ...)$y[rank(z)]
    dgz <- ppr.der(x = x, z = z, gz = gz, alpha = get("alpha", envir = parent.frame()))
    return(list(gz = gz, dgz = dgz))
}

scam.smoother <- function(z, y, w, const = "mpi", df = -1, ord = NA, lambda = NULL, ...){
    fit <- scam(y ~ s(z, bs = const, k = df, m = ord, sp = lambda), data = data.frame(y, z), weights = w, ...)
    gz <- predict(fit, data.frame(z = z), type = "response")
    dgz <- derivative.scam(fit)
    return(list(gz = as.vector(gz), dgz = as.vector(dgz$d)))
}

#' Gauss-Newton update for alphas.
#'
#' Computes the update of alphas in the GAIM by in a Gauss-Newton algorithm.
#'
#' @param r Numeric vector. The residual of the current Gauss-Newton step.
#' @param dg Numeric matrix. The partial derivative matrix of the current 
#'    Gauss-Newton step.
#' @param monotone Character in c("increasing", "decreasing") indicating the
#'    constarint of monotonicity to updates. If NULL, no constraint is added.
gn_update <- function(r, dg, w = rep(1 / length(r), length(r)), monotone = NULL,
  monotone.type = c("QP", "pya")){
  p <- ncol(dg)
  if (!is.null(monotone)){   
    if (!monotone %in% c("increasing", "decreasing")){
      stop("monotone must be either NULL, either one of 
        c('increasing', 'decreasing')")
    }
    monotone.type <- match.arg(monotone.type)
    delta <- switch(monotone.type,
      QP = update.QP(r, dg, w, monotone == "decreasing"),
      pya = update.pya(r, dg, w, monotone == "decreasing")
    )
  } else {
    delta <- coef(lm(r ~ 0 + dg, weights = w))
  }
  return(as.vector(delta))
}

update.QP <- function(y, x, w, decreasing = TRUE){
  p <- ncol(x)
  W <- diag(w)
  Dmat <- t(x) %*% W %*% x
  dvec <- 2 * t(y) %*% W %*% x
  Sigma <- matrix(0, p, p - 1)
  diag(Sigma) <- 1
  Sigma[row(Sigma) - col(Sigma) == 1] <- -1
  if (!decreasing) Sigma <- -1 * Sigma
  delta <- solve.QP(Dmat, dvec, Sigma)
  return(delta$solution)
}

update.pya <- function(y, x, w, decreasing = TRUE){
  p <- ncol(x)
  Sigma <- diag(p)
  if (decreasing){
    Sigma[lower.tri(Sigma, diag = TRUE)] <- -1
    Sigma[,1] <- 1    
  } else {
    Sigma[lower.tri(Sigma)] <- 1
  }
  x <- x %*% Sigma
  delta <- coef(lm(y ~ 0 + x, weights = w))
  delta[-1] <- exp(delta[-1])
  delta <- Sigma %*% delta
  return(delta)
}


#' Normalization of a vector of alphas
#'
#' Provides different ways to normalize a vector.
#'
#' @param alpha Numeric vector to normalize.
#' @param type Character indicating the type of normalization. List...
normalize <- function(alpha, type = "L2"){
  anorm <- switch(type,
    L2 = norm(alpha, "2"),
    L1 = norm(alpha, "1"),
    sum = sum(alpha),
    stop("type must be one of c('2', 'sum')")
  )
  return(alpha / anorm)
}